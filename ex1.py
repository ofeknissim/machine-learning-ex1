# -*- coding: utf-8 -*-
"""ex1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lQqOlU47jtXefvIMszJV2MPhoZeMz-lB

```
# This is formatted as code
```

Student 1: name: ofek ram nissim , i.d.: 318804820  , github: https://github.com/ofeknissim
Student 2: name: rafa olaru , i.d.: 211990908 , github:https://github.com/rafaolaru/IgorAsiignment1/tree/main
Student 3: name: amit amos , i.d.: 207927096 , github:

1. Load breast cancer dataset (**structured data**)

For more details about the data: https://scikit-learn.org/1.5/modules/generated/sklearn.datasets.load_breast_cancer.html
"""

from sklearn.datasets import load_breast_cancer
my_data = load_breast_cancer()
x = my_data.data
y_true = my_data.target

"""2. Split **my_data** to train and test:

- Define X_train, X_test, Y_train, Y_test
- Choose **test_size** for splitting **my_data**
- Use **train_test_split** (for details: https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html)
"""

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(x,y_true,test_size = 0.8 ,random_state=42)

"""3. Libraries"""

!pip install mlflow
!pip install mlflow scikit-learn

import mlflow
import mlflow.sklearn
from mlflow import log_param, log_metric

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score

import itertools
import pandas as pd

"""4. Define MLFlow experiment"""

EXPERIMENT_NAME = "trees_hyperparam"
mlflow.set_experiment(EXPERIMENT_NAME)
# MLFlow details: https://mlflow.org/docs/latest/ml/tracking/

"""5. Train **model_decision_tree**

- Library: sklearn.tree.DecisionTreeClassifier
- Data: X_train, Y_train
- **Essential**: explore and optimize DecisionTreeClassifier options   
"""

from sklearn.tree import DecisionTreeClassifier


criterion_list = ["gini", "entropy", "log_loss"]
splitter_list = ["best", "random"]
max_depth_list = [3, 5, 7]

param_grid = list(itertools.product(criterion_list, splitter_list, max_depth_list))

for criterion_list_value, splitter_list_value, max_depth_list_value in param_grid:
    with mlflow.start_run():

        # Log parameters
        mlflow.log_param("model_type", "DecisionTree")
        mlflow.log_param("gini", criterion_list_value)
        mlflow.log_param("entropy", splitter_list_value)
        mlflow.log_param("log_loss", max_depth_list_value)

        d_tree = DecisionTreeClassifier(criterion=criterion_list_value, splitter=splitter_list_value, max_depth=max_depth_list_value)
        d_tree.fit(X_train, Y_train)

        # run test prediction and calculate metrics:
        y_pred = d_tree.predict(X_test)
        # accuracy_score
        acc = accuracy_score(Y_test, y_pred)
        # precision_score
        pre = precision_score(Y_test, y_pred)
        # recall_score
        rec = recall_score(Y_test, y_pred)
        # f1_score
        f1 = f1_score(Y_test, y_pred)


        # Log metrics
        mlflow.log_metric("accuracy", acc)
        mlflow.log_metric("precision_score", pre)
        mlflow.log_metric("recall_score", rec)
        mlflow.log_metric("f1_score", f1)

"""6. Train model_random_forest
- Library: sklearn.ensemble.RandomForestClassifier
- Data: X_train, Y_train
- **Essential**: explore and optimize RandomForestClassifier options
"""

from sklearn.ensemble import RandomForestClassifier

n_estimators_list = [50, 100, 150]
criterion_list = ["gini", "entropy"]
min_samples_split_list = [2, 4]

param_grid = list(itertools.product(n_estimators_list, criterion_list, min_samples_split_list))

for n_estimators_list_value, criterion_list_value, min_samples_split_list_value in param_grid:
    with mlflow.start_run():

        # Log parameters
        mlflow.log_param("model_type", "RandomForest")
        mlflow.log_param("gini", n_estimators_list_value)
        mlflow.log_param("entropy", criterion_list_value)
        mlflow.log_param("log_loss", min_samples_split_list_value)

        # Train the model
        rf = RandomForestClassifier(n_estimators=n_estimators_list_value, criterion=criterion_list_value, min_samples_split=min_samples_split_list_value, random_state=42)
        rf.fit(X_train, Y_train)

        # run test prediction and calculate metrics:
        y_pred = rf.predict(X_test)
        # accuracy_score
        acc = accuracy_score(Y_test, y_pred)
        # precision_score
        pre = precision_score(Y_test, y_pred)
        # recall_score
        rec = recall_score(Y_test, y_pred)
        # f1_score
        f1 = f1_score(Y_test, y_pred)


        # Log metrics
        mlflow.log_metric("accuracy", acc)
        mlflow.log_metric("precision_score", pre)
        mlflow.log_metric("recall_score", rec)
        mlflow.log_metric("f1_score", f1)

"""7. Train model_adaboost

- Library: sklearn.ensemble.AdaBoostClassifier
- Data: X_train, Y_train
- **Essential**: explore and optimize AdaBoostClassifier options
"""

from sklearn.ensemble import AdaBoostClassifier

param_1_list = [50, 100, 150, 200, 250]
param_2_list = [0.1, 0.3, 0.5, 0.7, 1.0]
param_3_list = [50, 100, 150, 200, 250]

param_grid = list(itertools.product(param_1_list, param_2_list, param_3_list))

for param_1_value, param_2_value, param_3_value in param_grid:
    with mlflow.start_run():

        # Log parameters
        mlflow.log_param("model_type", "AdaBoostClassifier")
        mlflow.log_param("100 ", param_1_value)
        mlflow.log_param("150 ", param_2_value)
        mlflow.log_param("120 ", param_3_value)

        ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),n_estimators=param_1_value, learning_rate=param_2_value,random_state=42)
        ada.fit(X_train, Y_train)

        # run test prediction and calculate metrics:
        y_pred = ada.predict(X_test)
        # accuracy_score
        acc = accuracy_score(Y_test, y_pred)
        # precision_score
        pre = precision_score(Y_test, y_pred)
        # recall_score
        rec = recall_score(Y_test, y_pred)
        # f1_score
        f1 = f1_score(Y_test, y_pred)


        # Log metrics
        mlflow.log_metric("accuracy", acc)
        mlflow.log_metric("precision_score", pre)
        mlflow.log_metric("recall_score", rec)
        mlflow.log_metric("f1_score", f1)

"""8. Store the result"""

from google.colab import files
df = mlflow.search_runs(experiment_names=[EXPERIMENT_NAME])

df = df.drop(columns=[col for col in df.columns if "time" in col.lower()], errors="ignore")

df.to_excel("student_name_results.xlsx", index=False)

files.download("student_name_results.xlsx")